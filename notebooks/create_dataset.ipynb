{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset\n",
    "This notebook downloads Sentinel data from Descartes Labs to produce composited patches. Note: This requires acccess to Descartes Labs.\n",
    "\n",
    "## Inputs\n",
    "The notebook operates by loading a set of sampling sites from a geojson. If the geojson contains `Point` features, a bounding rect is constructed. If the geojson contains `Polygon` or `MultiPolygon` features, only pixels within the polygon will be extracted.\n",
    "\n",
    "The `download_mosaic` function attempts to mask clouds. However, cloudy pixels and patches can still come through.\n",
    "\n",
    "Pixels that fall outside of a polygon are also masked using a numpy masked array.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "### Patch Arrays:\n",
    "The output list of patch arrays is saved as a pickle. The arrays are not normalized. The dimensionality of each array is  `[num_samples][width][height][channels]`.\n",
    "A labels file is also written that corresponds to the label class defined in the notebook.\n",
    "\n",
    "### Image Plot:\n",
    "To log the data in a dataset, a grid of input images is exported along with the datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "parent_dir = os.path.split(os.getcwd())[0]\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from scripts import dl_utils\n",
    "from scripts.viz_tools import plot_image_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_patch_arrays(data, basepath, label_class):\n",
    "    with open(basepath + '_patch_arrays.pkl', \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    with open(basepath + '_patch_array_labels.pkl', \"wb\") as f:\n",
    "        pickle.dump([label_class] * len(data), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameters for data extraction\n",
    "### Attention: make sure to set appropriate label class!\n",
    "Negative sites = 0, Positive sites = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_file = 'v2.6_amazon_negatives_v2'\n",
    "data_dir = '../data/sampling_locations/'\n",
    "label_class = 0\n",
    "\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2021-02-01'\n",
    "METHOD = 'median'\n",
    "MOSAIC_PERIOD = 4  # the period over which to mosaic image data in months\n",
    "MAX_CLOUD = 0.25  # maximum cloud cover for a tile to be included in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or extract polygons from a sampling location\n",
    "with open(os.path.join(data_dir, sampling_file + '.geojson'), 'r') as f:\n",
    "    data = json.load(f)['features'] \n",
    "    \n",
    "# Set rect width in pixels. Only required for point samples. \n",
    "# Generally select a larger rect than intended patch size. Better to go with slightly bigger patches that can then be cropped.\n",
    "num_pixels = 48\n",
    "# Convert pixels to degrees. Heuristic, not geographically sound\n",
    "rect_width = np.round((num_pixels / 100) / 111.32, 4)    \n",
    "\n",
    "polygons = []\n",
    "for feature in data:\n",
    "    if feature['geometry']['type'] == 'Point':\n",
    "        polygons.append(dl_utils.rect_from_point(feature['geometry']['coordinates'], rect_width))\n",
    "    if feature['geometry']['type'] == 'MultiPolygon' or feature['geometry']['type'] == 'Polygon':\n",
    "        polygons.append(feature['geometry'])\n",
    "print(f'{len(polygons)} polygons loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_OUTPUT_DIR = f'../data/training_data/patch_composites_{num_pixels}px'\n",
    "if not os.path.exists(PATCH_OUTPUT_DIR):\n",
    "    os.makedirs(PATCH_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Sentinel Data\n",
    "Depending on the size of the dataset, this process can take a fair bit of time. Faster now, but can take ~20 sec / per patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = []\n",
    "for polygon in tqdm(polygons):\n",
    "    try:\n",
    "        data = dl_utils.SentinelData(polygon, START_DATE, END_DATE, MOSAIC_PERIOD, method=METHOD)\n",
    "        rect_width = rect_width\n",
    "        data.search_scenes()\n",
    "        data.download_scenes()\n",
    "        data.create_composites()\n",
    "        composites = data.composites\n",
    "        dates = data.composite_dates\n",
    "        bounds = data.metadata[0][\"wgs84Extent\"][\"coordinates\"][0][:-1]\n",
    "        data.compute_cloud_fraction()\n",
    "        patches += [p for p, cloud in zip(composites, data.cloud_fraction) if cloud < MAX_CLOUD]\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Keyboard Interrupt!\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print('Failure', polygon)\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View all images\n",
    "figure_file_path = os.path.join(PATCH_OUTPUT_DIR, f\"{sampling_file}_patches-Class_{label_class}-{START_DATE}-{END_DATE}-{METHOD}\")\n",
    "plot_image_grid(np.array(patches), file_path=figure_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_basepath = os.path.join(PATCH_OUTPUT_DIR, f\"{sampling_file}_{START_DATE}_{END_DATE}_period_{MOSAIC_PERIOD}_method_{METHOD}\")\n",
    "save_patch_arrays(patches, patch_basepath, label_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mining-detector')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "bec97cbb607180795486aa419a93884fe3d0b55501c3e5098d64200fe61c3ffb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
