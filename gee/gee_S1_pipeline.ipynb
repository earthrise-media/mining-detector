{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel 1 - Softcon embeddings \n",
    "\n",
    "Experimental notebook to gather Sentinel-1 data from Earth Engine and run foundation \n",
    "model inference. \n",
    "\n",
    "Depends on the external repo https://github.com/zhu-xlab/softcon and the out-of-repo model backbone that is linked on their README page. A local path to the cloned repo is specified in the cell below. \n",
    "\n",
    "The softcon model is trained on the SSL4EO-S12 dataset. Dataset statistics for normalization come from: https://arxiv.org/abs/2211.07044, App. 1, p. 8.\n",
    "\n",
    "Note that GEE data comes down in shape (h, w, bands), whereas rasterio, torch, etc. use (bands, h, w). For consistency we will assume the latter order after data download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T11:27:20.637403Z",
     "start_time": "2025-02-19T11:27:20.582538Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.transform import Affine\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gee\n",
    "import utils\n",
    "\n",
    "SOFTCON_PATH = 'softcon/'\n",
    "sys.path.append(SOFTCON_PATH)\n",
    "from models.dinov2 import vision_transformer \n",
    "\n",
    "SSL4EO_S1_STATS = {  \n",
    "    'VV': {'mean': -12.59, 'std': 5.26},\n",
    "    'VH': {'mean': -20.26, 'std': 5.91}\n",
    "}\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T11:57:46.736508Z",
     "start_time": "2025-02-20T11:57:46.623298Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(band, mean, std):\n",
    "    \"\"\"Normalize image data bandwise.\"\"\"\n",
    "    min_value = mean - 2 * std\n",
    "    max_value = mean + 2 * std\n",
    "    band = (band - min_value) / (max_value - min_value) * 255.0\n",
    "    band = np.clip(band, 0, 255).astype(np.float32)  # Zhu lab suggest uint8 here but the model requires float32\n",
    "    return band\n",
    "\n",
    "# We split a tile into geographic patches, or chips, with a size selected for object-oriented detection\n",
    "# applications. Experience indicates a chip size of order hundreds of meters rather than kms. Later, chips  \n",
    "# will be resized to match the input dimension expected by the model. It works. Why? It's a mystery.\n",
    "\n",
    "def cut_chips(tile_pixels, tile_info, geo_chip_size=32, stride_frac=2):\n",
    "    \"\"\"Split a large geographic tile into patches to be embedded.\"\"\"\n",
    "    stride = geo_chip_size // stride_frac\n",
    "    chips, chip_geoms = utils.chips_from_tile(np.moveaxis(tile_pixels, 0, -1), tile_info, geo_chip_size, stride)\n",
    "    chips = np.array(chips)\n",
    "    chips = np.moveaxis(chips, -1, 1)\n",
    "    chip_geoms.to_crs(\"EPSG:4326\", inplace=True)\n",
    "    return chips, chip_geoms\n",
    "\n",
    "def describe(arr):\n",
    "    \"\"\"Compute summary stats akin to pandas df.describe().\"\"\"\n",
    "    summary = {\n",
    "        \"count\": arr.size,\n",
    "        \"mean\": np.mean(arr),\n",
    "        \"std\": np.std(arr, ddof=1), \n",
    "        \"min\": np.min(arr),\n",
    "        \"25%\": np.percentile(arr, 25),\n",
    "        \"50% (median)\": np.median(arr),\n",
    "        \"75%\": np.percentile(arr, 75),\n",
    "        \"max\": np.max(arr),\n",
    "    }\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiling an AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T11:27:25.865462Z",
     "start_time": "2025-02-19T11:27:25.800436Z"
    }
   },
   "outputs": [],
   "source": [
    "region_name = 'tapajos_test_region'\n",
    "region = gpd.read_file(f'../data/boundaries/{region_name}.geojson').geometry[0].__geo_interface__\n",
    "\n",
    "tilesize = 1344 # previously 576, which was around the max size allowed for GEE export for 12-band imagery \n",
    "padding = 24\n",
    "\n",
    "start_date = datetime(2024, 12, 1)\n",
    "end_date = datetime(2024, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T11:28:01.083187Z",
     "start_time": "2025-02-19T11:28:00.961828Z"
    }
   },
   "outputs": [],
   "source": [
    "tiles = utils.create_tiles(region, tilesize=tilesize, padding=padding)\n",
    "print(f\"Created {len(tiles):,} tiles\")\n",
    "print(f'Sample tile data:\\n{tiles[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GEE S1 data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T11:28:10.377056Z",
     "start_time": "2025-02-19T11:28:07.900355Z"
    }
   },
   "outputs": [],
   "source": [
    "data_pipeline = gee.GEE_Data_Extractor(\n",
    "    tiles, \n",
    "    start_date, \n",
    "    end_date, \n",
    "    batch_size=500,\n",
    "    collection='S1'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T22:58:56.229511Z",
     "start_time": "2025-02-18T22:58:54.894600Z"
    }
   },
   "outputs": [],
   "source": [
    "data_pipeline.composite.bandNames().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T11:31:26.321978Z",
     "start_time": "2025-02-20T11:31:26.253127Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = 'S1datav2'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T20:00:50.534211Z",
     "start_time": "2025-02-20T19:06:16.730230Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_visual = True  # Save bandwise, uint8 copies of the data for easier visualization\n",
    "\n",
    "for tile in tqdm(tiles[20:]):\n",
    "    img, tile_info = data_pipeline.get_tile_data(tile)\n",
    "    img = utils.pad_patch(img, tile_info.tilesize)\n",
    "    \n",
    "    assert tile.tilesize == img.shape[0]\n",
    "    assert tile.tilesize == img.shape[1]\n",
    "    \n",
    "    img = img.astype('float32')\n",
    "    path = os.path.join(data_dir, f\"{region_name}S1_{tile.key}.tif\")\n",
    "    \n",
    "    # DLTile uses a pseudo-UTM system with only UTM North CRSs. Fix this. \n",
    "    if tile.bounds[1] < 0 and tile.crs.upper().startswith(\"EPSG:326\"):\n",
    "        utm_zone = tile.crs.split(\":\")[1][-2:] \n",
    "        crs = f\"EPSG:327{utm_zone}\"\n",
    "        geotrans = list(tile.geotrans)\n",
    "        geotrans[3] = geotrans[3] + 10000000\n",
    "        \n",
    "    else:\n",
    "        crs = tile.crs\n",
    "        geotrans = tile.geotrans\n",
    "        \n",
    "\n",
    "    profile = {\n",
    "        'count': img.shape[-1],\n",
    "        'height': img.shape[0],\n",
    "        'width': img.shape[1],\n",
    "        'crs': crs,\n",
    "        'transform': Affine.from_gdal(*geotrans),\n",
    "        'dtype': img.dtype\n",
    "    }\n",
    "    \n",
    "    with rasterio.open(path, 'w', **profile) as f:\n",
    "        for band in range(2):\n",
    "            f.write(img[:, :, band], band + 1)\n",
    "            \n",
    "    if save_visual:\n",
    "        profile.update({'count': 1, 'dtype': 'uint8'})\n",
    "        for i, (band, stats) in enumerate(SSL4EO_S1_STATS.items()):\n",
    "            with rasterio.open(path.split('.tif')[0] + f'{band}.tif', 'w', **profile) as f:\n",
    "                raster = img[:, :, i].reshape(1, *img[:, :, i].shape)\n",
    "                raster = normalize(raster, stats['mean'], stats['std'])\n",
    "                f.write(raster)\n",
    "                print(describe(raster))\n",
    "\n",
    "    print(f\"Saved {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Bulk reload data from disk for inspection. For inference, tiles are loaded one by one to save RAM. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T11:41:36.532995Z",
     "start_time": "2025-02-20T11:41:36.463170Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'S1datav2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T11:42:14.651191Z",
     "start_time": "2025-02-20T11:42:14.593114Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "available_paths = glob.glob(f'{data_dir}/{region_name}*.tif')\n",
    "paths = []\n",
    "for tile in tiles[:2]:\n",
    "    for path in available_paths:\n",
    "        if tile.key in path and 'VV' not in path and 'VH' not in path:\n",
    "            paths.append(path)\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T11:42:25.800530Z",
     "start_time": "2025-02-20T11:42:25.712931Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pixels = []\n",
    "for path in paths:\n",
    "    with rasterio.open(path, 'r') as f:\n",
    "        S1image = f.read()\n",
    "        pixels.append(S1image)\n",
    "    \n",
    "pixels = np.array(pixels)\n",
    "pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T11:48:34.365752Z",
     "start_time": "2025-02-20T11:48:33.995017Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for p in pixels:\n",
    "    for arr in p:\n",
    "        print(describe(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T11:42:28.439669Z",
     "start_time": "2025-02-20T11:42:27.893366Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "to_view = pixels[:3]\n",
    "\n",
    "fig, axes = plt.subplots(len(to_view), 2, figsize=(10, 10*len(to_view)))\n",
    "\n",
    "if axes.ndim == 1:\n",
    "    axes = axes[np.newaxis, :]  \n",
    "\n",
    "for row,img in zip(axes, to_view):\n",
    "    for (ax, band, band_name) in zip(row, img, data_pipeline.bandIds):\n",
    "        ax.imshow(band)\n",
    "        ax.set_title(band_name)\n",
    "        ax.axis(\"off\") \n",
    "\n",
    "# plt.savefig(f'{data_dir}/{region_name}_S1to{end_date.date().isoformat()}.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T11:28:17.564368Z",
     "start_time": "2025-02-19T11:28:17.129641Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "model_chip_size = 224\n",
    "\n",
    "# For running on Mac Mx chip\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\") \n",
    "\n",
    "print(f'Device: {device}')\n",
    "\n",
    "model = vision_transformer.__dict__['vit_small'](\n",
    "    img_size=model_chip_size,\n",
    "    patch_size=14,\n",
    "    in_chans=2,\n",
    "    block_chunks=0,\n",
    "    init_values=1e-5,\n",
    "    num_register_tokens=0,\n",
    ")\n",
    "\n",
    "model_name = 'B2_vits14_softcon.pth'\n",
    "ckpt_vits14 = torch.load(os.path.join(SOFTCON_PATH, f'pretrained/{model_name}'))\n",
    "model.load_state_dict(ckpt_vits14)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T01:24:22.242339Z",
     "start_time": "2025-02-20T22:57:02.810230Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "geo_chip_size = 32\n",
    "batch_size = 128 \n",
    "feature_columns = [f\"vit-dino-patch14_{i}\" for i in range(features.shape[-1])] \n",
    "\n",
    "gdfs = []\n",
    "for tile in tqdm(tiles):\n",
    "    path = os.path.join(data_dir, f\"{region_name}S1_{tile.key}.tif\")\n",
    "    with rasterio.open(path, 'r') as f:\n",
    "        pixels = f.read()\n",
    "    \n",
    "    normed = [normalize(band, stats['mean'], stats['std']) for band, stats in zip(pixels, SSL4EO_S1_STATS.values())]\n",
    "    normed = np.array(normed)\n",
    "    \n",
    "    chips, chip_geoms = cut_chips(normed, tile, geo_chip_size=geo_chip_size)\n",
    "    tensor = torch.from_numpy(chips)\n",
    "    if geo_chip_size != model_chip_size:\n",
    "        tensor = transforms.Resize((model_chip_size, model_chip_size), antialias=False).__call__(tensor)\n",
    "\n",
    "    print(f'Input tensor shape {tensor.shape}')\n",
    "    tensor = tensor.to(device)\n",
    "    \n",
    "    batch_outputs = []\n",
    "    for i in tqdm(range(0, len(tensor), batch_size)):\n",
    "        batch = tensor[i : i + batch_size]\n",
    "        with torch.no_grad():\n",
    "            batch_output = model(batch)\n",
    "        batch_outputs.append(batch_output)\n",
    "    batch_outputs = torch.cat(batch_outputs).cpu().numpy()    \n",
    "    \n",
    "    features_df = gpd.pd.DataFrame(batch_outputs, columns=feature_columns)\n",
    "    gdf = gpd.pd.concat([chip_geoms, features_df], axis=1)\n",
    "    gdfs.append(gdf)\n",
    "    \n",
    "gdf = gpd.pd.concat(gdfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T01:24:31.740468Z",
     "start_time": "2025-02-21T01:24:22.245472Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(region_name):\n",
    "    os.mkdir(region_name)\n",
    "\n",
    "gdf.to_parquet(f\"{region_name}/{region_name}_{model_name.split('.pth')[0]}_{geo_chip_size}chip_S1to{end_date.date().isoformat()}.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Optional embedding quantization to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T11:09:28.712093Z",
     "start_time": "2025-02-21T11:09:15.566075Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Inspect and adjust upper / lower bound to ensure sufficient variance after quantization.\n",
    "# (In principle the bounds should be set once across all S1 embeddings.)\n",
    "gdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T11:12:22.437818Z",
     "start_time": "2025-02-21T11:12:21.125611Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def quantize(embeddings, lower_bound=-5, upper_bound=5):\n",
    "    clipped = np.clip(embeddings, lower_bound, upper_bound)\n",
    "    normalized = (clipped - lower_bound) / (upper_bound - lower_bound)\n",
    "    scaled = normalized * 255\n",
    "    return scaled.astype(np.uint8)\n",
    "\n",
    "quantized = quantize(gdf.drop(columns='geometry').to_numpy())\n",
    "features_df = gpd.pd.DataFrame(quantized, columns=feature_columns)\n",
    "q_gdf = gpd.pd.concat([gdf['geometry'], features_df], axis=1)\n",
    "q_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T11:12:31.929842Z",
     "start_time": "2025-02-21T11:12:27.493715Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "q_gdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T14:35:51.190509Z",
     "start_time": "2025-02-19T14:35:44.003036Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "q_gdf.to_parquet(f\"{region_name}/{region_name}_{model_name.split('.pth')[0]}_{geo_chip_size}chip_S1to{end_date.date().isoformat()}_quant.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
