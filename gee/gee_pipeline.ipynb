{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import keras\n",
    "\n",
    "import gee\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M3 Pro\n",
      "\n",
      "systemMemory: 36.00 GB\n",
      "maxCacheSize: 13.50 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 08:19:13.235037: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-08 08:19:13.235141: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model_name = '48px_v3.1_2023-12-02'\n",
    "\n",
    "region_name = 'test_region'\n",
    "\n",
    "tile_size = 576 # this is the around the max size that GEE exports allow with 12-band imagery\n",
    "tile_padding = 24\n",
    "\n",
    "start_date = datetime(2023, 5, 1)\n",
    "end_date = datetime(2023, 7, 1)\n",
    "clear_threshold = 0.6\n",
    "\n",
    "pred_threshold = 0.5\n",
    "\n",
    "# load the model up here to make processing printout cleaner\n",
    "model = keras.models.load_model(f'../models/{model_name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 08:19:17.912366: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-12-08 08:19:17.968206: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139,346 hectares were analyzed in 0 minutes and 36 seconds\n",
      "At this speed, you could process an area the size of Rhode Island in 81 seconds\n",
      "and the Amazon basin in 49.5 hours (2.1 days)\n"
     ]
    }
   ],
   "source": [
    "# start a timer\n",
    "start = datetime.now()\n",
    "\n",
    "region = gpd.read_file(f'../data/boundaries/{region_name}.geojson').geometry[0].__geo_interface__\n",
    "\n",
    "tiles = utils.create_tiles(region, tile_size, tile_padding)\n",
    "\n",
    "data_pipeline = gee.S2_Data_Extractor(\n",
    "    tiles, \n",
    "    start_date, \n",
    "    end_date, \n",
    "    clear_threshold, \n",
    "    batch_size=500\n",
    "    )\n",
    "preds = data_pipeline.make_predictions(model, pred_threshold=pred_threshold)\n",
    "\n",
    "# end the timer\n",
    "end = datetime.now()\n",
    "\n",
    "# print the time it took to run the pipeline\n",
    "area_m2 = len(tiles) * (tile_size * 10) ** 2\n",
    "# convert the meters squared to hectares\n",
    "area_ha = area_m2 / 10000\n",
    "duration = end - start\n",
    "minutes, seconds = divmod(duration.total_seconds(), 60)\n",
    "print(f\"{area_ha:,.0f} hectares were analyzed in {minutes:.0f} minutes and {seconds:.0f} seconds\")\n",
    "print(f\"At this speed, you could process an area the size of Rhode Island in {313900 * duration.total_seconds() / area_ha:.0f} seconds\")\n",
    "minutes, seconds = divmod(2203 * 313900 * duration.total_seconds() / area_ha, 60)\n",
    "# ~2203 Rhode Islands in the Amazon basin\n",
    "print(f\"and the Amazon basin in {minutes / 60:,.1f} hours ({minutes / 60 / 24:,.1f} days)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 chips with predictions above 0.5\n"
     ]
    }
   ],
   "source": [
    "# write the predictions to a file\n",
    "print(len(preds), 'chips with predictions above', pred_threshold)\n",
    "# write the predictions to a file\n",
    "model_version_name = '_'.join(model_name.split('_')[0:2])\n",
    "# if the outputs directory does not exist, create it\n",
    "if not os.path.exists(f'../data/outputs/{model_version_name}'):\n",
    "    os.makedirs(f'../data/outputs/{model_version_name}')\n",
    "time_period = f\"{start_date.month}_{start_date.year}-{end_date.month}_{end_date.year}\"\n",
    "preds.to_file(f\"../data/outputs/{model_version_name}/{region_name}_{model_version_name}_{pred_threshold:.2f}_{time_period}.geojson\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
