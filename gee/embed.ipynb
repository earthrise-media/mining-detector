{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings \n",
    "\n",
    "Train a linear probe on the SSL4EO foundation model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T14:15:35.092093Z",
     "start_time": "2025-11-06T14:15:27.451772Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "import glob\n",
    "import joblib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import legacy as legacy_optimizers\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gee\n",
    "import model_library\n",
    "import tile_utils\n",
    "\n",
    "SSL4EO_PATH = 'SSL4EO'\n",
    "\n",
    "data_dir = '../data/training_patches2025-10-21T23:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:48:41.072310Z",
     "start_time": "2025-11-05T12:48:41.069422Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(data_dir, bands_to_use=None):\n",
    "    \"\"\"\n",
    "    Loads all images from '0' and '1' subdirectories into RAM.\n",
    "\n",
    "    Returns:\n",
    "        X: np.ndarray of shape (num_samples, H, W, C)\n",
    "        y: np.ndarray of shape (num_samples,)\n",
    "    \"\"\"\n",
    "    files_class_0 = glob.glob(os.path.join(data_dir, '0', '*.tif'))\n",
    "    files_class_1 = glob.glob(os.path.join(data_dir, '1', '*.tif'))\n",
    "    files = files_class_0 + files_class_1\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .tif files found in '0' or '1' subdirectories of {data_dir}\")\n",
    "\n",
    "    imgs, labels = [], []\n",
    "\n",
    "    for file_path in files:\n",
    "        import rasterio\n",
    "        with rasterio.open(file_path) as src:\n",
    "            arr = src.read()  # (bands, H, W)\n",
    "            if bands_to_use is not None:\n",
    "                arr = arr[bands_to_use, :, :]\n",
    "            arr = np.moveaxis(arr, 0, -1)  # (H, W, C)\n",
    "            arr = arr.astype(np.float32) / 10000.0\n",
    "            imgs.append(arr)\n",
    "\n",
    "        label_str = os.path.basename(os.path.dirname(file_path))\n",
    "        labels.append(int(label_str))\n",
    "\n",
    "    X = np.stack(imgs, axis=0)\n",
    "    y = np.array(labels, dtype=np.int32)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:48:41.223759Z",
     "start_time": "2025-11-05T12:48:41.073033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input data\n",
    "\n",
    "positive_paths =  glob.glob(f\"{data_dir}/train/1/*.tif\")\n",
    "negative_paths = glob.glob(f\"{data_dir}/train/0/*.tif\")\n",
    "pos_val_paths = glob.glob(f\"{data_dir}/val/1/*.tif\")\n",
    "neg_val_paths = glob.glob(f\"{data_dir}/val/0/*.tif\")\n",
    "print(f\"{len(positive_paths)} train positives\")\n",
    "print(f\"{len(negative_paths)} train negatives\")\n",
    "print(f\"{len(pos_val_paths)} val positives\")\n",
    "print(f\"{len(neg_val_paths)} val negatives\")\n",
    "\n",
    "X_train, y_train = load_dataset(os.path.join(data_dir, 'train'))\n",
    "X_val, y_val = load_dataset(os.path.join(data_dir, 'val'))\n",
    "print(f'Training data shape: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:48:51.376257Z",
     "start_time": "2025-11-05T12:48:51.370716Z"
    }
   },
   "outputs": [],
   "source": [
    "model_chip_size = 224\n",
    "\n",
    "# For running on Mac Mx chip\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\") \n",
    "\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:49:43.537310Z",
     "start_time": "2025-11-05T12:49:42.296794Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model - SSL4EO\n",
    "\n",
    "embed_model_name = 'dino_vit_small_patch16_224.pt'\n",
    "\n",
    "embed_model = torch.load(os.path.join(SSL4EO_PATH, f'pretrained/{embed_model_name}'), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:49:43.593588Z",
     "start_time": "2025-11-05T12:49:43.538432Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_model.to(device)\n",
    "embed_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:49:43.596538Z",
     "start_time": "2025-11-05T12:49:43.594332Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_chip_size = 48\n",
    "batch_size = 4 \n",
    "output_dim = embed_model.norm.normalized_shape[0]\n",
    "feature_columns = [f\"vit-dino-patch14_{i}\" for i in range(output_dim)] \n",
    "\n",
    "def quantize(embeddings, lower_bound=-5, upper_bound=5):\n",
    "    clipped = np.clip(embeddings, lower_bound, upper_bound)\n",
    "    normalized = (clipped - lower_bound) / (upper_bound - lower_bound)\n",
    "    scaled = normalized * 255\n",
    "    return scaled.astype(np.uint8)\n",
    "\n",
    "quantized = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T21:03:28.670816Z",
     "start_time": "2025-10-21T21:03:28.657783Z"
    }
   },
   "outputs": [],
   "source": [
    "def embed(X, y, model, batch_size=4, geo_chip_size=48, model_chip_size=224, quantized=False):\n",
    "    \n",
    "    tensor = torch.from_numpy(X)\n",
    "    \n",
    "    batch_outputs = []\n",
    "    for i in tqdm(range(0, len(tensor), batch_size)):\n",
    "        batch = tensor[i : i + batch_size]\n",
    "        batch = batch.permute(0, 3, 1, 2)\n",
    "\n",
    "        if geo_chip_size != model_chip_size:\n",
    "            batch = F.interpolate(batch, size=(model_chip_size, model_chip_size), \n",
    "                                  mode='bicubic', align_corners=False)\n",
    "        \n",
    "        batch = batch.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_output = model(batch)\n",
    "            if isinstance(batch_output, dict):\n",
    "                key = list(batch_output.keys())[0]\n",
    "                batch_output = batch_output[key]\n",
    "            batch_outputs.append(batch_output.cpu())\n",
    "            del batch, batch_output \n",
    "\n",
    "    batch_outputs = torch.cat(batch_outputs).numpy()    \n",
    "    features = quantize(batch_outputs) if quantized else batch_outputs\n",
    "    features_df = pd.DataFrame(features, columns=feature_columns)\n",
    "    features_df['label'] = y\n",
    "\n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T21:03:31.908292Z",
     "start_time": "2025-10-21T21:03:31.597689Z"
    }
   },
   "outputs": [],
   "source": [
    "df_val = embed(X_val, y_val, embed_model)\n",
    "df_val['split'] = 'val'\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T21:03:34.426125Z",
     "start_time": "2025-10-21T21:03:33.997898Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = embed(X_train, y_train, embed_model)#, batch_size=1)\n",
    "df_train['split'] = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T21:03:38.984262Z",
     "start_time": "2025-10-21T21:03:38.958024Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_val, df_train])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T21:03:41.793013Z",
     "start_time": "2025-10-21T21:03:41.777075Z"
    }
   },
   "outputs": [],
   "source": [
    "df[['label', 'split']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T21:03:56.724918Z",
     "start_time": "2025-10-21T21:03:56.540737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optional. If there were previous training embeddings, load and concat them here: \n",
    "prev = pd.read_parquet('../data/training_patches2025-10-21T13:25ssl4eo.parquet')\n",
    "print(f\"Prev len: {len(prev)}\")\n",
    "df = pd.concat([prev, df])\n",
    "print(f\"New len: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T21:04:02.740329Z",
     "start_time": "2025-10-21T21:04:02.265187Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_parquet(data_dir + 'ssl4eo.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or restore embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:49:22.020181Z",
     "start_time": "2025-11-05T12:49:21.590775Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(data_dir + 'ssl4eo.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:49:23.458815Z",
     "start_time": "2025-11-05T12:49:23.423663Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df[df.split == 'train']\n",
    "df_val = df[df.split == 'val']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T21:05:13.274431Z",
     "start_time": "2025-10-21T21:05:13.268428Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = '48px_v1.3SSL4EO-MLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:49:13.184971Z",
     "start_time": "2025-11-05T12:49:13.173490Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_tf_dataset(X, y, batch_size=8, shuffle=True):\n",
    "    \"\"\"\n",
    "    X, y: NumPy arrays \n",
    "    batch_size: int\n",
    "    shuffle: whether to shuffle dataset\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(X))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=8)  # small buffer reduces GPU memory spikes\n",
    "    return dataset\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint_dir = \"../checkpoints\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "try: \n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"{model_name}{timestamp}.h5\")\n",
    "except NameError: \n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"best_model{timestamp}.h5\")\n",
    "\n",
    "# Consider adding something dynamic like this to checkpoint_path: \"/model_{epoch:02d}_{val_acc:.4f}.h5\" \n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor=\"val_acc\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"max\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "earlystop_cb = EarlyStopping(\n",
    "    monitor=\"val_acc\",\n",
    "    patience=20,\n",
    "    mode=\"max\",\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_cb = ReduceLROnPlateau(\n",
    "    monitor=\"val_acc\",\n",
    "    factor=0.33,\n",
    "    patience=10,\n",
    "    min_delta=0.005,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:49:49.423261Z",
     "start_time": "2025-11-05T12:49:49.333376Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = make_tf_dataset(df_train[feature_columns].values, df_train['label'].values, shuffle=True)\n",
    "val_ds = make_tf_dataset(df_val[feature_columns].values, df_val['label'].values, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T21:05:23.305567Z",
     "start_time": "2025-10-21T21:05:23.251643Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp = model_library.MLP(input_dim=384, hidden_layers=(64,16))\n",
    "mlp.compile(\n",
    "    optimizer=legacy_optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name=\"acc\")],\n",
    "    run_eagerly=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T16:34:00.388961Z",
     "start_time": "2025-10-21T16:34:00.125937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Or reload to continue training\n",
    "model_name = '48px_v1.1.1SSL4EO-MLP20251021_172507'\n",
    "mlp = tf.keras.models.load_model(f'../checkpoints/{model_name}.h5')\n",
    "\n",
    "mlp.compile(\n",
    "    optimizer=legacy_optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name=\"acc\")],\n",
    "    run_eagerly=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T21:49:36.329106Z",
     "start_time": "2025-10-21T21:05:27.018958Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50, \n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint_cb, reduce_lr_cb]#, earlystop_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T18:57:22.078613Z",
     "start_time": "2025-10-21T18:57:22.025614Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch = 31\n",
    "resolution = 48\n",
    "version_number = '1.2SSL4EO-MLP'\n",
    "current_date = date.today()\n",
    "model_name = f'{resolution}px_v{version_number}ep{epoch}_{current_date.isoformat()}'\n",
    "model_path = f\"../checkpts-tmp/{model_name}.h5\"\n",
    "assert not os.path.exists(model_path), f\"Model {model_path} already exists\"\n",
    "\n",
    "mlp.save(model_path)\n",
    "print(f\"Saved {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T14:15:49.269406Z",
     "start_time": "2025-11-06T14:15:48.963506Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reload a saved model \n",
    "model_name = '48px_v0.X_SSL4EO-MLPensemble_2025-10-21'\n",
    "mlp = tf.keras.models.load_model(f'../models/{model_name}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T14:15:58.329465Z",
     "start_time": "2025-11-06T14:15:58.303988Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:50:23.919090Z",
     "start_time": "2025-11-05T12:50:11.353804Z"
    }
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    preds = mlp.predict(val_ds, verbose=1)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T22:00:37.514438Z",
     "start_time": "2025-10-21T22:00:37.512200Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = preds.squeeze()\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:50:23.922048Z",
     "start_time": "2025-11-05T12:50:23.920287Z"
    }
   },
   "outputs": [],
   "source": [
    "# For an ensemble\n",
    "preds = preds.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:50:24.049799Z",
     "start_time": "2025-11-05T12:50:23.922738Z"
    }
   },
   "outputs": [],
   "source": [
    "def acc_curve(preds, y_true, thresholds=np.arange(.01, 1.01, .01)):\n",
    "    \"\"\"Compute accuracy curve as function of threshold\"\"\"\n",
    "    score = [np.sum((preds >= t).astype('int') == y_true) / len(y_true) for t in thresholds]\n",
    "    plt.plot(thresholds, score)\n",
    "    plt.ylabel('Success Rate')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title(f\"Optimal Threshold: {thresholds[np.argmax(score)]:.2f} w/ accuracy {score[np.argmax(score)]:.2f}\")\n",
    "\n",
    "acc_curve(preds, df_val['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:50:24.206663Z",
     "start_time": "2025-11-05T12:50:24.052775Z"
    }
   },
   "outputs": [],
   "source": [
    "def f1_curve(preds, y_true, thresholds=np.arange(.01, 1.01, .01)):\n",
    "    \"\"\"Compute F1 curve.\"\"\"\n",
    "    f1s = []\n",
    "    for t in thresholds:\n",
    "        y_pred = (preds >= t)\n",
    "        f1s.append(f1_score(y_true, y_pred))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(thresholds, f1s, label='Patchwise')\n",
    "    ax.set_xlabel('Threshold')\n",
    "    ax.set_ylabel('F1 score')\n",
    "    ax.legend(loc='lower left')\n",
    "    plt.title(f\"Optimal Threshold: {thresholds[np.argmax(f1s)]:.2f} w/ F1 {f1s[np.argmax(f1s)]:.2f}\")\n",
    "    return fig, ax\n",
    "\n",
    "f1_curve(preds, df_val['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:50:46.466473Z",
     "start_time": "2025-11-05T12:50:46.440409Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.925\n",
    "report = classification_report(df_val['label'].values, preds > threshold, target_names=['No Mine', 'Mine'], output_dict=True)\n",
    "report = pd.DataFrame(report).transpose()\n",
    "report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:50:24.226587Z",
     "start_time": "2025-11-05T12:50:24.218333Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.99\n",
    "report = classification_report(df_val['label'].values, preds > threshold, target_names=['No Mine', 'Mine'], output_dict=True)\n",
    "report = pd.DataFrame(report).transpose()\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T12:51:25.267712Z",
     "start_time": "2025-11-05T12:51:25.245863Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.925\n",
    "target_names = ['No Mine', 'Mine']\n",
    "training_dataset = 'collected_locations2025-10-21T23:00.geojson'\n",
    "\n",
    "model_path = f'../checkpts-tmp/{model_name}.h5'\n",
    "with open(model_path.split('.h5')[0] + f\"_config-t{threshold}.txt\", 'w') as f:\n",
    "    f.write(f'Training dataset: {training_dataset}')\n",
    "    f.write(f\"\\nBatch Size: {batch_size}\")\n",
    "    f.write(f'\\n\\nClassification Report at {threshold}\\n')\n",
    "    f.write(classification_report(df_val['label'].values, preds > threshold, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Sklearn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T23:25:27.915663Z",
     "start_time": "2025-09-11T23:25:27.909120Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "layer_sizes = (64, 16)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=layer_sizes, n_iter_no_change=40, max_iter=1000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T23:25:43.312923Z",
     "start_time": "2025-09-11T23:25:28.487641Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mlp.fit(df_train[feature_columns], df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T23:25:43.350906Z",
     "start_time": "2025-09-11T23:25:43.322769Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds = mlp.predict_proba(df.loc[df.split == 'val', feature_columns])\n",
    "preds = preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-11T23:27:13.573205Z",
     "start_time": "2025-09-11T23:27:13.315059Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "now = datetime.today().isoformat()[:16]\n",
    "model_path = f'../checkpts-tmp/SSL4EO-MLP{\"-\".join([str(s) for s in layer_sizes])}_{now}.joblib'\n",
    "print(f'Model saved to: {model_path}')\n",
    "joblib.dump(model, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
